# ğŸ·ï¸ Taller: SegmentaciÃ³n SemÃ¡ntica con SAM y DeepLab en Deep Learning

## ğŸ“… Fecha
`2025-06-25`

---

## ğŸ¯ Objetivo del Notebook

Explorar y comparar modelos de segmentaciÃ³n semÃ¡ntica de imÃ¡genes utilizando tÃ©cnicas de Deep Learning. El taller implementa y prueba dos enfoques avanzados: **SAM (Segment Anything Model)** y **DeepLab**, mostrando cÃ³mo aplicar ambos para segmentar objetos y regiones en imÃ¡genes.

---

## ğŸ§  Conceptos Aprendidos

- [x] Principios de la segmentaciÃ³n semÃ¡ntica en Deep Learning
- [x] Uso del modelo DeepLab (PyTorch/TensorFlow)
- [x] Uso de SAM (Segment Anything Model) de Meta AI
- [x] Preprocesamiento de imÃ¡genes para segmentaciÃ³n
- [x] VisualizaciÃ³n y comparaciÃ³n de mÃ¡scaras segmentadas
- [x] AnÃ¡lisis de ventajas y limitaciones de cada enfoque

---

## ğŸ”§ Herramientas y Entornos

- Google Colab (Python 3, GPU opcional)
- PyTorch y/o TensorFlow
- torchvision, numpy, matplotlib
- [Segment Anything Model (SAM)](https://github.com/facebookresearch/segment-anything) de Meta AI
- Modelos pre-entrenados DeepLab (por ejemplo, DeepLabV3)

---

## ğŸ“ Estructura del Proyecto

```
Taller - Taller segmentacion semantica sam deeplab/
â”œâ”€â”€ sementacion_semantica_sam_deelearnig.ipynb   # Notebook principal con todo el flujo
â””â”€â”€ (imÃ¡genes de ejemplo, si se usan)
```

---

## ğŸ§ª ImplementaciÃ³n

### ğŸ”¹ Etapas realizadas

1. InstalaciÃ³n de dependencias y descarga de modelos pre-entrenados.
2. Carga y preprocesamiento de imÃ¡genes de ejemplo.
3. AplicaciÃ³n de SAM para segmentaciÃ³n automÃ¡tica de regiones.
4. AplicaciÃ³n de DeepLabV3 (u otro) para segmentaciÃ³n semÃ¡ntica clÃ¡sica.
5. VisualizaciÃ³n de resultados: mÃ¡scaras, overlays y comparaciÃ³n lado a lado.
6. DiscusiÃ³n sobre diferencias, ventajas y casos de uso de cada mÃ©todo.

---

### ğŸ”¹ Fragmento real del cÃ³digo (ejemplo tÃ­pico de flujo)

```python
# Ejemplo de inferencia con SAM
import torch
import numpy as np
from segment_anything import SamPredictor, sam_model_registry

sam = sam_model_registry["vit_h"](checkpoint="sam_vit_h.pth").to(device)
predictor = SamPredictor(sam)
predictor.set_image(image)
masks, scores, logits = predictor.predict(point_coords=points, point_labels=labels)

# Ejemplo de inferencia con DeepLabV3
import torchvision
deeplab = torchvision.models.segmentation.deeplabv3_resnet101(pretrained=True).eval()
input_tensor = preprocess(image)
with torch.no_grad():
    output = deeplab(input_tensor.unsqueeze(0))["out"]
mask = output.argmax(1).squeeze().cpu().numpy()
```

---

## ğŸ“Š Resultados Visuales

![imag](masks_animation.gif)

---

## ğŸ§© Prompts Usados

```text
Â¿CÃ³mo uso SAM (Segment Anything Model) para segmentar regiones en imÃ¡genes en Colab?
Â¿CÃ³mo aplico DeepLab para segmentaciÃ³n semÃ¡ntica en imÃ¡genes?
Â¿CÃ³mo comparo visualmente los resultados de dos modelos de segmentaciÃ³n?
```

---

## ğŸ’¬ ReflexiÃ³n Final

- SAM ofrece una segmentaciÃ³n automÃ¡tica y flexible, Ãºtil para distintos dominios y objetos, pero requiere mÃ¡s recursos.
- DeepLab sigue siendo una opciÃ³n sÃ³lida y eficiente para segmentaciÃ³n semÃ¡ntica clÃ¡sica y tareas supervisadas.
- La combinaciÃ³n de ambos permite explorar ventajas prÃ¡cticas y entender el estado del arte en segmentaciÃ³n.

---

## âœ… Checklist de Entrega

- [x] Notebook funcional y comentado
- [x] Ejemplos con imÃ¡genes reales
- [x] ComparaciÃ³n visual entre SAM y DeepLab
- [x] README claro y detallado

---
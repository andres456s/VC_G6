# ğŸ§¬ Taller: Embeddings Visuales con CLIP y ReducciÃ³n PCA

## ğŸ“… Fecha
`2025-06-28`

---

## ğŸ¯ Objetivo del Notebook

Explorar y visualizar representaciones (embeddings) de imÃ¡genes generadas por el modelo CLIP de OpenAI, aplicando reducciÃ³n de dimensionalidad con PCA (AnÃ¡lisis de Componentes Principales). El taller permite observar cÃ³mo CLIP "entiende" imÃ¡genes y cÃ³mo se pueden agrupar visualmente segÃºn su similitud semÃ¡ntica.

---

## ğŸ§  Conceptos Aprendidos

- [x] GeneraciÃ³n de embeddings visuales con CLIP
- [x] Preprocesamiento y carga de mÃºltiples imÃ¡genes
- [x] ReducciÃ³n de dimensionalidad con PCA para visualizaciÃ³n 2D
- [x] VisualizaciÃ³n de agrupamientos semÃ¡nticos en el espacio reducido
- [x] RelaciÃ³n entre visiÃ³n computacional y aprendizaje profundo

---

## ğŸ”§ Herramientas y Entornos

- Google Colab (Python 3, GPU opcional)
- [CLIP (OpenAI)](https://github.com/openai/CLIP)
- scikit-learn (`PCA`)
- torch, torchvision, PIL, matplotlib, numpy

---

## ğŸ“ Estructura del Proyecto

```
Taller - Taller embeddings visuales clip pca/
â””â”€â”€ Taller_Taller_embeddings_visuales_clip_pca.ipynb   # Notebook principal
```

---

## ğŸ§ª ImplementaciÃ³n

### ğŸ”¹ Etapas realizadas

1. InstalaciÃ³n y carga del modelo CLIP y dependencias.
2. SelecciÃ³n/carga de un conjunto de imÃ¡genes de ejemplo.
3. ExtracciÃ³n de embeddings visuales para cada imagen usando CLIP.
4. AplicaciÃ³n de PCA para reducir la dimensionalidad de los embeddings.
5. VisualizaciÃ³n 2D de los embeddings proyectados con etiquetas o miniaturas.
6. InterpretaciÃ³n de agrupamientos y relaciones semÃ¡nticas en el espacio reducido.

---

### ğŸ”¹ CÃ³digo real usado para embeddings y reducciÃ³n

```python
import clip
import torch
from PIL import Image
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
import numpy as np

device = "cuda" if torch.cuda.is_available() else "cpu"
model, preprocess = clip.load("ViT-B/32", device=device)

images = [Image.open(path) for path in image_paths]
image_tensors = [preprocess(img).unsqueeze(0).to(device) for img in images]
image_features = []

with torch.no_grad():
    for tensor in image_tensors:
        feats = model.encode_image(tensor).cpu().numpy().flatten()
        image_features.append(feats)

image_features = np.array(image_features)

# ReducciÃ³n de dimensionalidad con PCA
pca = PCA(n_components=2)
embeddings_2d = pca.fit_transform(image_features)

# VisualizaciÃ³n
plt.figure(figsize=(8,6))
plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1])
for i, label in enumerate(image_labels):
    plt.annotate(label, (embeddings_2d[i, 0], embeddings_2d[i, 1]))
plt.title("VisualizaciÃ³n 2D de Embeddings CLIP reducidos con PCA")
plt.show()
```

---

## ğŸ“Š Resultados Visuales

-![img](gif.gif)

---

## ğŸ§© Prompts Usados

```text
Â¿CÃ³mo obtengo embeddings visuales de imÃ¡genes con CLIP?
Â¿CÃ³mo reduzco la dimensionalidad de embeddings con PCA y los visualizo?
Â¿CÃ³mo puedo visualizar agrupamientos semÃ¡nticos de imÃ¡genes usando CLIP?
```

---

## ğŸ’¬ ReflexiÃ³n Final

- Visualizar los embeddings de CLIP ayuda a entender cÃ³mo los modelos asocian imÃ¡genes similares.
- PCA es Ãºtil para exploraciÃ³n y prototipado visual, aunque puede perder informaciÃ³n respecto al espacio original.
- Como mejora, se podrÃ­a probar t-SNE o UMAP para reducciÃ³n no lineal, o explorar embeddings de texto junto a los de imagen.

---

## âœ… Checklist de Entrega

- [x] Notebook funcional y comentado
- [x] Ejemplo con conjunto de imÃ¡genes y visualizaciÃ³n 2D
- [x] InterpretaciÃ³n y reflexiÃ³n sobre los resultados
- [x] README claro y detallado

---